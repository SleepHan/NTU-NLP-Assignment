{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "513c09f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random, os, string\n",
    "from torchtext import data , datasets\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "\n",
    "os.environ['GENSIM_DATA_DIR'] = os.path.join(os.getcwd(), 'gensim-data')\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c413bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['How', 'tall', 'is', 'Prince', 'Charles', '?'], 'label': 'NUM'}\n",
      "\n",
      "Label distribution in training set:\n",
      "- ABBR: 69 samples (1.58%)\n",
      "- DESC: 930 samples (21.32%)\n",
      "- ENTY: 1000 samples (22.93%)\n",
      "- HUM: 978 samples (22.42%)\n",
      "- LOC: 668 samples (15.31%)\n",
      "- NUM: 717 samples (16.44%)\n",
      "Total samples: 4362, Sum of percentages: 100.00%\n"
     ]
    }
   ],
   "source": [
    "### Part 0: Dataset Preparation\n",
    "\n",
    "# For tokenization\n",
    "TEXT = data.Field ( tokenize = 'spacy', tokenizer_language = 'en_core_web_sm', include_lengths = True )\n",
    "\n",
    "# For multi - class classification labels\n",
    "LABEL = data.LabelField ()\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Load the TREC dataset\n",
    "# Train / Validation / Test split\n",
    "train_data, test_data = datasets.TREC.splits( TEXT, LABEL, fine_grained = False )\n",
    "\n",
    "train_data, validation_data = train_data.split(\n",
    "    split_ratio=0.8,\n",
    "    stratified=True,\n",
    "    strata_field='label',\n",
    "    random_state=random.seed(42)\n",
    ")\n",
    "print(vars(train_data.examples[0]))\n",
    "\n",
    "\n",
    "# Count how many samples per label in the train set\n",
    "label_counts = Counter([ex.label for ex in train_data.examples])\n",
    "total_examples = len(train_data)\n",
    "\n",
    "print(\"\\nLabel distribution in training set:\")\n",
    "for label, count in sorted(label_counts.items()):\n",
    "    percentage = (count / total_examples) * 100\n",
    "    print(f\"- {label}: {count} samples ({percentage:.2f}%)\")\n",
    "\n",
    "# Optional sanity check: total percentages should sum â‰ˆ 100%\n",
    "total_percentage = sum((count / total_examples) * 100 for count in label_counts.values())\n",
    "print(f\"Total samples: {total_examples}, Sum of percentages: {total_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442ff1d4",
   "metadata": {},
   "source": [
    "# Part 1: Prepare Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e9040ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size (with specials): 8118\n",
      "Vocabulary size (no specials): 8116\n"
     ]
    }
   ],
   "source": [
    "#### a) Size of Vocabulary formed from training data according to tokenization method\n",
    "# Vocabulary size (includes specials like <unk>, <pad>)\n",
    "TEXT.build_vocab(train_data, min_freq=1)\n",
    "vocab_size = len(TEXT.vocab)\n",
    "print(\"Vocabulary Size (with specials):\", vocab_size)\n",
    "\n",
    "vocab_wo_specials = len([w for w in TEXT.vocab.stoi if w not in {TEXT.unk_token, TEXT.pad_token}])\n",
    "print(\"Vocabulary size (no specials):\", vocab_wo_specials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1507b5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of OOV word types (overall): 420\n",
      "\n",
      "OOV word types per topic label:\n",
      "- ABBR: 20 OOV types (out of 148, rate=13.51%)\n",
      "- DESC: 118 OOV types (out of 2278, rate=5.18%)\n",
      "- ENTY: 157 OOV types (out of 2979, rate=5.27%)\n",
      "- HUM: 141 OOV types (out of 3055, rate=4.62%)\n",
      "- LOC: 79 OOV types (out of 1762, rate=4.48%)\n",
      "- NUM: 76 OOV types (out of 1880, rate=4.04%)\n"
     ]
    }
   ],
   "source": [
    "#### b) How many OOV words exist in your training data?\n",
    "####    What is the number of OOV words for each topic category?\n",
    "w2v = api.load(\"word2vec-google-news-300\")\n",
    "w2v_vocab = w2v.key_to_index\n",
    "\n",
    "# Get training vocab tokens (types), excluding specials\n",
    "specials = {TEXT.unk_token, TEXT.pad_token}\n",
    "train_vocab_types = [w for w in TEXT.vocab.stoi.keys() if w not in specials]\n",
    "\n",
    "# Overall OOV types in training vocab\n",
    "oov_types_overall = {w for w in train_vocab_types if w not in w2v_vocab}\n",
    "print(\"Number of OOV word types (overall):\", len(oov_types_overall))\n",
    "\n",
    "# OOV types per label (unique types per category across its sentences)\n",
    "label_to_oov_types = defaultdict(set)\n",
    "label_to_total_types = defaultdict(set)\n",
    "\n",
    "for ex in train_data.examples:\n",
    "    label = ex.label\n",
    "    # Count by unique types per sentence to avoid overcounting repeats\n",
    "    for w in set(ex.text):\n",
    "        label_to_total_types[label].add(w)\n",
    "        if w not in specials and w not in w2v_vocab:\n",
    "            label_to_oov_types[label].add(w)\n",
    "\n",
    "print(\"\\nOOV word types per topic label:\")\n",
    "for label in sorted(label_to_total_types.keys()):\n",
    "    num_oov = len(label_to_oov_types[label])\n",
    "    num_types = len(label_to_total_types[label])\n",
    "    rate = (num_oov / num_types) if num_types > 0 else 0.0\n",
    "    print(f\"- {label}: {num_oov} OOV types (out of {num_types}, rate={rate:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6a5315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### c) OOV mitigation strategy (No transformer-based language models allowed)\n",
    "# Implement your solution in your source code. Show the corresponding code snippet.\n",
    "# 1. Fast Text Model Implementatation\n",
    "# Load FastText with subword info (pretrained on Wikipedia)\n",
    "# First download is large; cached afterwards\n",
    "\n",
    "# 2. Modelling Unknown (<UNK>) token approach\n",
    "# Make the <unk> vector informative and trainable by initializing it\n",
    "# as the mean of available pretrained vectors.\n",
    "\n",
    "# Loading fasttext model\n",
    "fatter_fasttext_bin = load_facebook_model('crawl-300d-2M-subword/crawl-300d-2M-subword.bin')\n",
    "embedding_dim = fatter_fasttext_bin.wv.vector_size\n",
    "\n",
    "# Build embedding matrix aligned to TEXT.vocab\n",
    "num_tokens = len(TEXT.vocab)\n",
    "emb_matrix = np.zeros((num_tokens, embedding_dim), dtype=np.float32)\n",
    "\n",
    "# torchtext 0.4.0: TEXT.vocab.itos is index->token, stoi is token->index\n",
    "pad_tok = TEXT.pad_token\n",
    "unk_tok = TEXT.unk_token\n",
    "\n",
    "# Getting index of <unk> in vocab\n",
    "unk_index = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "known_vecs = []\n",
    "\n",
    "for idx, token in enumerate(TEXT.vocab.itos):\n",
    "    # Skip specials here; we will set them explicitly below\n",
    "    if token in {pad_tok, unk_tok}:\n",
    "        continue\n",
    "\n",
    "    vec = fatter_fasttext_bin.wv[token]\n",
    "    emb_matrix[idx] = vec\n",
    "    known_vecs.append(vec)\n",
    "\n",
    "if len(known_vecs) > 0:\n",
    "    unk_mean = torch.tensor(np.mean(known_vecs, axis=0), dtype=torch.float32)\n",
    "else:\n",
    "    unk_mean = torch.empty(embedding_dim).uniform_(-0.05, 0.05)\n",
    "with torch.no_grad():\n",
    "    emb_matrix[unk_index] = unk_mean\n",
    "\n",
    "# Create Embedding layer initialized with FastText\n",
    "fatter_embedding = torch.nn.Embedding(num_tokens, embedding_dim, padding_idx=TEXT.vocab.stoi[TEXT.pad_token])\n",
    "fatter_embedding.weight.data.copy_(torch.from_numpy(emb_matrix))\n",
    "\n",
    "torch.save(fatter_embedding, 'embedding_weights_fatter_fasttext.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1e7172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plots: trec_top20_tsne.png, trec_top20_pca.png\n",
      "ABBR: ['stand', 'abbreviation', 'mean', 'computer', 'cnn', 'letters', 'national', 'bureau', 'investigation', 'acronym', 'form', 'cpr', 'reading', 'classified', 'ads', 'dsl', 'scsi', 'washington', 'shield', 'psi']\n",
      "DESC: ['mean', 'origin', 'difference', 'word', 'find', 'come', 'work', 'people', 'term', 'meaning', 'causes', 'like', 't', 'school', 'definition', 'called', 'time', 'happened', 'famous', 'computer']\n",
      "ENTY: ['fear', 'called', 'kind', 'world', 'best', 'film', 'color', 'war', 'movie', 'novel', 'book', 'word', 'animal', 'drink', 'term', 'english', 'sport', 'known', 'play', 'use']\n",
      "HUM: ['president', 'company', 'wrote', 'world', 'famous', 'invented', 'won', 'character', 'movie', 'team', 'baseball', 'new', 'tv', 'portrayed', 'known', 'american', 'actor', 'star', 'king', 'played']\n",
      "LOC: ['country', 'city', 'state', 'world', 'largest', 'find', 'countries', 'located', 'river', 'highest', 'live', 'capital', 'airport', 'mountain', 'island', 'information', 'america', 'states', 'boasts', 'american']\n",
      "NUM: ['year', 'long', 'people', 'old', 'average', 'day', 'american', 'world', 'population', 'number', 'war', 'years', 'game', 'cost', 'live', 'born', 'big', 'die', 'date', 'money']\n"
     ]
    }
   ],
   "source": [
    "#### d) Select the 20 most frequent words from each topic category in the training set (removing\n",
    "# stopwords if necessary). Retrieve their pretrained embeddings (from Word2Vec or GloVe).\n",
    "# Project these embeddings into 2D space (using e.g., t-SNE or Principal Component Analysis).\n",
    "# Plot the points in a scatter plot, color-coded by their topic category. Attach your plot here.\n",
    "# Analyze your findings.\n",
    "\n",
    "# Build per-label token frequency (lowercased, stopwords/punct filtered)\n",
    "label_to_counter = defaultdict(Counter)\n",
    "valid_chars = set(string.ascii_letters)\n",
    "\n",
    "def is_valid_token(tok: str) -> bool:\n",
    "    t = tok.strip(\"'\\\"\")\n",
    "    if len(t) == 0:\n",
    "        return False\n",
    "    # Keep purely alphabetic tokens to avoid punctuation/numbers\n",
    "    return t.isalpha()\n",
    "\n",
    "for ex in train_data.examples:\n",
    "    label = ex.label\n",
    "    for tok in ex.text:\n",
    "        tok_l = tok.lower()\n",
    "        if tok_l in STOP_WORDS:\n",
    "            continue\n",
    "        if not is_valid_token(tok_l):\n",
    "            continue\n",
    "        label_to_counter[label][tok_l] += 1\n",
    "\n",
    "# Select top 20 per label that exist in Word2Vec\n",
    "topk = 20\n",
    "label_to_top_tokens = {}\n",
    "for label, ctr in label_to_counter.items():\n",
    "    selected = []\n",
    "    for tok, _ in ctr.most_common():\n",
    "        if tok in w2v.key_to_index:\n",
    "            selected.append(tok)\n",
    "        if len(selected) >= topk:\n",
    "            break\n",
    "    label_to_top_tokens[label] = selected\n",
    "\n",
    "# Collect embeddings and labels\n",
    "points = []\n",
    "point_labels = []\n",
    "point_words = []\n",
    "for label, toks in label_to_top_tokens.items():\n",
    "    for tok in toks:\n",
    "        vec = w2v.get_vector(tok)\n",
    "        points.append(vec)\n",
    "        point_labels.append(label)\n",
    "        point_words.append(tok)\n",
    "\n",
    "if len(points) > 0:\n",
    "    X = np.vstack(points)\n",
    "\n",
    "    # 2D projections\n",
    "    tsne_2d = TSNE(n_components=2, random_state=42, init=\"pca\", perplexity=30).fit_transform(X)\n",
    "    pca_2d = PCA(n_components=2, random_state=42).fit_transform(X)\n",
    "\n",
    "    # Assign colors per label\n",
    "    unique_labels = sorted(set(point_labels))\n",
    "    color_map = {lab: plt.cm.tab10(i % 10) for i, lab in enumerate(unique_labels)}\n",
    "\n",
    "    def plot_scatter(Y2, title: str, fname: str):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        for lab in unique_labels:\n",
    "            idxs = [i for i, l in enumerate(point_labels) if l == lab]\n",
    "            plt.scatter(Y2[idxs, 0], Y2[idxs, 1], c=[color_map[lab]], label=lab, alpha=0.8, s=40)\n",
    "            # Light word annotations (optional; can clutter)\n",
    "            for i in idxs:\n",
    "                plt.annotate(point_words[i], (Y2[i, 0], Y2[i, 1]), fontsize=7, alpha=0.7)\n",
    "        plt.legend(title=\"TREC label\")\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fname, dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "    plot_scatter(tsne_2d, \"Top-20 per TREC label (Word2Vec) - t-SNE\", \"trec_top20_tsne.png\")\n",
    "    plot_scatter(pca_2d, \"Top-20 per TREC label (Word2Vec) - PCA\", \"trec_top20_pca.png\")\n",
    "\n",
    "    print(\"Saved plots: trec_top20_tsne.png, trec_top20_pca.png\")\n",
    "    for lab in unique_labels:\n",
    "        print(f\"{lab}: {label_to_top_tokens[lab]}\")\n",
    "else:\n",
    "    print(\"No points collected for visualization. Check filtering or embedding availability.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f3b12aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(8166, 300, padding_idx=1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fatter_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214decac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of classes: 6\n",
      "Classes: ['ENTY', 'HUM', 'DESC', 'NUM', 'LOC', 'ABBR']\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Build vocabulary for labels\n",
    "LABEL.build_vocab(train_data)\n",
    "num_classes = len(LABEL.vocab)\n",
    "print(f\"\\nNumber of classes: {num_classes}\")\n",
    "print(f\"Classes: {LABEL.vocab.itos}\")\n",
    "\n",
    "# Create iterators for batching\n",
    "def create_iterators(train_data, validation_data, test_data, batch_size):\n",
    "    train_iterator = data.BucketIterator(\n",
    "        train_data,\n",
    "        batch_size=batch_size,\n",
    "        sort_key=lambda x: len(x.text),\n",
    "        sort_within_batch=True,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    val_iterator = data.BucketIterator(\n",
    "        validation_data,\n",
    "        batch_size=batch_size,\n",
    "        sort_key=lambda x: len(x.text),\n",
    "        sort_within_batch=True,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    test_iterator = data.BucketIterator(\n",
    "        test_data,\n",
    "        batch_size=batch_size,\n",
    "        sort_key=lambda x: len(x.text),\n",
    "        sort_within_batch=True,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    return train_iterator, val_iterator, test_iterator\n",
    "\n",
    "\n",
    "class RNN_Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple RNN for topic classification with multiple aggregation strategies\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, \n",
    "                 n_layers=1, bidirectional=False, dropout=0.5, \n",
    "                 padding_idx=0, pretrained_embeddings=None,\n",
    "                 aggregation='last'):\n",
    "        super(RNN_Classifier, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.aggregation = aggregation  # 'last', 'mean', 'max', 'attention'\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        \n",
    "        # Initialize with pretrained embeddings\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "        \n",
    "        # Make embeddings learnable (updated during training)\n",
    "        self.embedding.weight.requires_grad = True\n",
    "        \n",
    "        # RNN layer\n",
    "        self.rnn = nn.RNN(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=n_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if n_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Attention mechanism for aggregation\n",
    "        if aggregation == 'attention':\n",
    "            rnn_output_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "            self.attention = nn.Linear(rnn_output_dim, 1)\n",
    "        \n",
    "        # Fully connected output layer\n",
    "        rnn_output_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        self.fc = nn.Linear(rnn_output_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        # text: [batch_size, seq_len]\n",
    "        # text_lengths: [batch_size]\n",
    "        \n",
    "        # Embed the input\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        # embedded: [batch_size, seq_len, embedding_dim]\n",
    "        \n",
    "        # Pack the padded sequences\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded, text_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        \n",
    "        # Pass through RNN\n",
    "        packed_output, hidden = self.rnn(packed_embedded)\n",
    "        # packed_output: packed sequence of [batch_size, seq_len, hidden_dim * num_directions]\n",
    "        # hidden: [n_layers * num_directions, batch_size, hidden_dim]\n",
    "        \n",
    "        # Unpack the sequences\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        # output: [batch_size, seq_len, hidden_dim * num_directions]\n",
    "        \n",
    "        # Aggregate word representations to sentence representation\n",
    "        if self.aggregation == 'last':\n",
    "            # Use the last hidden state\n",
    "            if self.bidirectional:\n",
    "                # Concatenate last states from forward and backward\n",
    "                hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "            else:\n",
    "                hidden = hidden[-1,:,:]\n",
    "            sentence_repr = hidden\n",
    "            \n",
    "        elif self.aggregation == 'mean':\n",
    "            # Mean pooling over all outputs (ignoring padding)\n",
    "            # Create mask for padding\n",
    "            batch_size, seq_len, hidden_size = output.size()\n",
    "            mask = torch.arange(seq_len, device=device).unsqueeze(0) < text_lengths.unsqueeze(1)\n",
    "            mask = mask.unsqueeze(2).float()  # [batch_size, seq_len, 1]\n",
    "            \n",
    "            # Apply mask and compute mean\n",
    "            masked_output = output * mask\n",
    "            sum_output = masked_output.sum(dim=1)\n",
    "            sentence_repr = sum_output / text_lengths.unsqueeze(1).float()\n",
    "            \n",
    "        elif self.aggregation == 'max':\n",
    "            # Max pooling over all outputs\n",
    "            sentence_repr, _ = torch.max(output, dim=1)\n",
    "            \n",
    "        elif self.aggregation == 'attention':\n",
    "            # Attention mechanism\n",
    "            # Compute attention scores\n",
    "            attn_scores = self.attention(output).squeeze(2)  # [batch_size, seq_len]\n",
    "            \n",
    "            # Mask padding positions\n",
    "            mask = torch.arange(output.size(1), device=device).unsqueeze(0) < text_lengths.unsqueeze(1)\n",
    "            attn_scores = attn_scores.masked_fill(~mask, float('-inf'))\n",
    "            \n",
    "            # Apply softmax\n",
    "            attn_weights = torch.softmax(attn_scores, dim=1).unsqueeze(1)  # [batch_size, 1, seq_len]\n",
    "            \n",
    "            # Weighted sum\n",
    "            sentence_repr = torch.bmm(attn_weights, output).squeeze(1)  # [batch_size, hidden_dim * num_directions]\n",
    "        \n",
    "        # Apply dropout\n",
    "        sentence_repr = self.dropout(sentence_repr)\n",
    "        \n",
    "        # Pass through fully connected layer\n",
    "        output = self.fc(sentence_repr)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count trainable parameters\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def train_epoch(model, iterator, optimizer, criterion, device, l1_lambda=0.0, l2_lambda=0.0):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for batch in iterator:\n",
    "        text, text_lengths = batch.text\n",
    "        labels = batch.label\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(text, text_lengths)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(predictions, labels)\n",
    "        \n",
    "        # Add L1 regularization\n",
    "        if l1_lambda > 0:\n",
    "            l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "            loss = loss + l1_lambda * l1_norm\n",
    "        \n",
    "        # Add L2 regularization (can also use weight_decay in optimizer)\n",
    "        if l2_lambda > 0:\n",
    "            l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n",
    "            loss = loss + l2_lambda * l2_norm\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Store predictions and labels for metrics\n",
    "        preds = torch.argmax(predictions, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return epoch_loss / len(iterator), accuracy, f1\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion, device, return_predictions=False):\n",
    "    \"\"\"Evaluate the model\"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            labels = batch.label\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = model(text, text_lengths)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(predictions, labels)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Store predictions and labels\n",
    "            probs = torch.softmax(predictions, dim=1)\n",
    "            preds = torch.argmax(predictions, dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    # Calculate AUC-ROC (one-vs-rest for multiclass)\n",
    "    try:\n",
    "        all_probs_array = np.array(all_probs)\n",
    "        all_labels_bin = label_binarize(all_labels, classes=range(num_classes))\n",
    "        auc_roc = roc_auc_score(all_labels_bin, all_probs_array, average='weighted', multi_class='ovr')\n",
    "    except:\n",
    "        auc_roc = 0.0\n",
    "    \n",
    "    if return_predictions:\n",
    "        return epoch_loss / len(iterator), accuracy, f1, auc_roc, all_preds, all_labels\n",
    "    \n",
    "    return epoch_loss / len(iterator), accuracy, f1, auc_roc\n",
    "\n",
    "\n",
    "def train_model(model, train_iterator, val_iterator, optimizer, criterion, \n",
    "                n_epochs, device, patience=5, l1_lambda=0.0, l2_lambda=0.0,\n",
    "                save_path='best_model.pt'):\n",
    "    \"\"\"\n",
    "    Train the model with early stopping\n",
    "    \"\"\"\n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    print(f\"\\nStarting training for {n_epochs} epochs...\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Model parameters: {count_parameters(model):,}\")\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc, train_f1 = train_epoch(\n",
    "            model, train_iterator, optimizer, criterion, device, l1_lambda, l2_lambda\n",
    "        )\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_acc, val_f1, val_auc = evaluate(model, val_iterator, criterion, device)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = divmod(end_time - start_time, 60)\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print(f'Epoch: {epoch+1:02}/{n_epochs} | Time: {int(epoch_mins)}m {int(epoch_secs)}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}% | Train F1: {train_f1:.4f}')\n",
    "        print(f'\\tVal Loss: {val_loss:.4f} | Val Acc: {val_acc*100:.2f}% | Val F1: {val_f1:.4f} | Val AUC: {val_auc:.4f}')\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f'\\t>>> New best model saved with Val Acc: {val_acc*100:.2f}%')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f'\\t>>> No improvement. Patience: {patience_counter}/{patience}')\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f'\\nEarly stopping triggered after epoch {epoch+1}')\n",
    "                break\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'val_losses': val_losses,\n",
    "        'val_accs': val_accs,\n",
    "        'best_val_acc': best_val_acc\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_per_topic(model, iterator, device):\n",
    "    \"\"\"Evaluate model performance per topic category\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    topic_correct = defaultdict(int)\n",
    "    topic_total = defaultdict(int)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            labels = batch.label\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = model(text, text_lengths)\n",
    "            preds = torch.argmax(predictions, dim=1)\n",
    "            \n",
    "            # Count per topic\n",
    "            for pred, label in zip(preds.cpu().numpy(), labels.cpu().numpy()):\n",
    "                topic_name = LABEL.vocab.itos[label]\n",
    "                topic_total[topic_name] += 1\n",
    "                if pred == label:\n",
    "                    topic_correct[topic_name] += 1\n",
    "    \n",
    "    # Calculate accuracy per topic\n",
    "    topic_accuracies = {}\n",
    "    for topic in sorted(topic_total.keys()):\n",
    "        acc = topic_correct[topic] / topic_total[topic] if topic_total[topic] > 0 else 0\n",
    "        topic_accuracies[topic] = acc\n",
    "        print(f'{topic}: {topic_correct[topic]}/{topic_total[topic]} = {acc*100:.2f}%')\n",
    "    \n",
    "    return topic_accuracies\n",
    "\n",
    "\n",
    "def plot_training_curves(history, save_prefix='rnn'):\n",
    "    \"\"\"Plot training and validation curves\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss curve\n",
    "    axes[0].plot(history['train_losses'], label='Train Loss', marker='o')\n",
    "    axes[0].plot(history['val_losses'], label='Val Loss', marker='s')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy curve\n",
    "    axes[1].plot([acc*100 for acc in history['train_accs']], label='Train Acc', marker='o')\n",
    "    axes[1].plot([acc*100 for acc in history['val_accs']], label='Val Acc', marker='s')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_prefix}_training_curves.png', dpi=200)\n",
    "    plt.close()\n",
    "    print(f'Saved training curves to {save_prefix}_training_curves.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b3e62050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PART 2: RNN MODEL TRAINING\n",
      "================================================================================\n",
      "\n",
      ">>> Training Baseline RNN Model\n",
      "Configuration: Hidden=256, Layers=1, Dropout=0.5, LR=0.001, Batch=64\n",
      "\n",
      "Starting training for 50 epochs...\n",
      "Device: cpu\n",
      "Model parameters: 2,594,190\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.LongTensor of size 8x64]', '[torch.LongTensor of size 64]')\n",
      "\t[.label]:[torch.LongTensor of size 64]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConfiguration: Hidden=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHIDDEN_DIM\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Layers=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN_LAYERS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Dropout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDROPOUT\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, LR=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLEARNING_RATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Batch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBATCH_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Train baseline model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m baseline_history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbaseline_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrnn_baseline_best.pt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     49\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Load best model and evaluate on test set\u001b[39;00m\n\u001b[32m     52\u001b[39m baseline_model.load_state_dict(torch.load(\u001b[33m'\u001b[39m\u001b[33mrnn_baseline_best.pt\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 288\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_iterator, val_iterator, optimizer, criterion, n_epochs, device, patience, l1_lambda, l2_lambda, save_path)\u001b[39m\n\u001b[32m    285\u001b[39m start_time = time.time()\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m train_loss, train_acc, train_f1 = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1_lambda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_lambda\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[38;5;66;03m# Evaluate on validation set\u001b[39;00m\n\u001b[32m    293\u001b[39m val_loss, val_acc, val_f1, val_auc = evaluate(model, val_iterator, criterion, device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 182\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, iterator, optimizer, criterion, device, l1_lambda, l2_lambda)\u001b[39m\n\u001b[32m    179\u001b[39m optimizer.zero_grad()\n\u001b[32m    181\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m predictions = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_lengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[32m    185\u001b[39m loss = criterion(predictions, labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Han\\Desktop\\School\\AY2526_Sem1\\SC4002 - NLP\\nlpEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Han\\Desktop\\School\\AY2526_Sem1\\SC4002 - NLP\\nlpEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 98\u001b[39m, in \u001b[36mRNN_Classifier.forward\u001b[39m\u001b[34m(self, text, text_lengths)\u001b[39m\n\u001b[32m     94\u001b[39m embedded = \u001b[38;5;28mself\u001b[39m.dropout(\u001b[38;5;28mself\u001b[39m.embedding(text))\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# embedded: [batch_size, seq_len, embedding_dim]\u001b[39;00m\n\u001b[32m     96\u001b[39m \n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# Pack the padded sequences\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m packed_embedded = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpack_padded_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_lengths\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_sorted\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    100\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# Pass through RNN\u001b[39;00m\n\u001b[32m    103\u001b[39m packed_output, hidden = \u001b[38;5;28mself\u001b[39m.rnn(packed_embedded)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Han\\Desktop\\School\\AY2526_Sem1\\SC4002 - NLP\\nlpEnv\\Lib\\site-packages\\torch\\nn\\utils\\rnn.py:338\u001b[39m, in \u001b[36mpack_padded_sequence\u001b[39m\u001b[34m(input, lengths, batch_first, enforce_sorted)\u001b[39m\n\u001b[32m    336\u001b[39m     sorted_indices = sorted_indices.to(\u001b[38;5;28minput\u001b[39m.device)\n\u001b[32m    337\u001b[39m     batch_dim = \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msorted_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    340\u001b[39m data, batch_sizes = _VF._pack_padded_sequence(\u001b[38;5;28minput\u001b[39m, lengths, batch_first)\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _packed_sequence_init(data, batch_sizes, sorted_indices, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mIndexError\u001b[39m: index out of range in self"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PART 2: RNN MODEL TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get pretrained embeddings from Part 1\n",
    "pretrained_embeddings = fatter_embedding.weight.data.clone()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters for baseline\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_DIM = 256\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.5\n",
    "N_EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "PATIENCE = 10\n",
    "\n",
    "# Create data iterators\n",
    "train_iterator, val_iterator, test_iterator = create_iterators(\n",
    "    train_data, validation_data, test_data, BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Initialize baseline model\n",
    "baseline_model = RNN_Classifier(\n",
    "    vocab_size=len(TEXT.vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=num_classes,\n",
    "    n_layers=N_LAYERS,\n",
    "    bidirectional=False,\n",
    "    dropout=DROPOUT,\n",
    "    padding_idx=TEXT.vocab.stoi[TEXT.pad_token],\n",
    "    pretrained_embeddings=pretrained_embeddings,\n",
    "    aggregation='last'\n",
    ").to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(baseline_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"\\n>>> Training Baseline RNN Model\")\n",
    "print(f\"Configuration: Hidden={HIDDEN_DIM}, Layers={N_LAYERS}, Dropout={DROPOUT}, LR={LEARNING_RATE}, Batch={BATCH_SIZE}\")\n",
    "\n",
    "# Train baseline model\n",
    "baseline_history = train_model(\n",
    "    baseline_model, train_iterator, val_iterator, optimizer, criterion,\n",
    "    n_epochs=N_EPOCHS, device=device, patience=PATIENCE,\n",
    "    save_path='rnn_baseline_best.pt'\n",
    ")\n",
    "\n",
    "# Load best model and evaluate on test set\n",
    "baseline_model.load_state_dict(torch.load('rnn_baseline_best.pt'))\n",
    "test_loss, test_acc, test_f1, test_auc = evaluate(baseline_model, test_iterator, criterion, device)\n",
    "\n",
    "print(f\"\\n>>> Baseline Model Test Results:\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Test AUC-ROC: {test_auc:.4f}\")\n",
    "\n",
    "# Topic-wise accuracy\n",
    "print(f\"\\n>>> Topic-wise Accuracy (Baseline):\")\n",
    "baseline_topic_acc = evaluate_per_topic(baseline_model, test_iterator, device)\n",
    "\n",
    "# Plot training curves\n",
    "plot_training_curves(baseline_history, save_prefix='rnn_baseline')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
